No Country - Prueba T√©cnica: Generaci√≥n y Guardado de Embeddings

Contexto

No Country es una plataforma que valida el comportamiento del talento digital a trav√©s de simulaciones laborales colaborativas. El Squad de Datos transforma interacciones en evidencia estructurada para perfiles y dashboards. Esta prueba t√©cnica implementa la Funcionalidad 1: Generaci√≥n y Guardado de Embeddings, priorizando una base s√≥lida para an√°lisis sem√°ntico y consultas RAG.

Justificaci√≥n de la Elecci√≥n

Eleg√≠ la Funcionalidad 1 porque es fundamental para el an√°lisis sem√°ntico y las consultas RAG, herramientas clave para entender patrones de comportamiento y generar insights personalizados. Implementarla primero garantiza un sistema s√≥lido que procese textos de manera eficiente, genere embeddings y elimine duplicados, mejorando la validaci√≥n de talento. Adem√°s, decid√≠ priorizar esta funcionalidad sobre el an√°lisis de sentimiento y t√≥picos para asegurar una base confiable antes de agregar procesos m√°s avanzados.

Stack Utilizado

Lenguaje: Python
Framework: FastAPI (para el endpoint)
LLM/Embeddings: sentence-transformers/all-MiniLM-L6-v2 (generaci√≥n de embeddings de 384 dimensiones)
Almacenamiento Vectorial: Supabase PGVector
Base de Datos: Supabase PostgreSQL
Control de Versiones: GitHub
Librer√≠as Adicionales: pandas, nltk, transformers, psycopg2, supabase, emoji, langdetect, sentencepiece, sacremoses

Implementaci√≥n

La soluci√≥n procesa textos de interacciones, genera embeddings, los almacena en Supabase, y ofrece un endpoint para verificar duplicados. Se implement√≥ limpieza de texto para mejorar la calidad de los embeddings.
1. Estructura del Proyecto
no_country_prueba_tecnica/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ processing.py      # Limpieza de texto y traducci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ connect.py        # Conexi√≥n y guardado en Supabase
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generate.py       # Generaci√≥n de embeddings
‚îú‚îÄ‚îÄ sample_data.csv           # 100 registros de prueba
‚îú‚îÄ‚îÄ test_generate_embeddings.py # Script para procesar y guardar embeddings
‚îú‚îÄ‚îÄ main.py                   # API FastAPI con endpoint /check_embedding
‚îú‚îÄ‚îÄ requirements.txt          # Dependencias
‚îú‚îÄ‚îÄ .env                     # Credenciales de Supabase
‚îî‚îÄ‚îÄ .gitignore               # Ignorar .env y archivos temporales

2. Limpieza de Texto

M√≥dulo: src/data/processing.py
Procesos:
Detecta idioma con langdetect.
Traduce textos en ingl√©s a espa√±ol usando Helsinki-NLP/opus-mt-en-es, preservando t√©rminos de IT (por ejemplo, "bug", "fix", "ASAP").
Convierte a min√∫sculas, elimina URLs, menciones (@usuario), puntuaci√≥n, y stopwords (espa√±ol).
Extrae emoticones con emoji para an√°lisis futuro.
Genera cleaned_text (no almacenado) y text_hash (MD5) para identificar duplicados.


Ejemplo:
Entrada: "Need to fix bugs ASAP @devteam https://example.com"
Salida: cleaned_text: "necesitar fix bugs asap", emoticons: ""



3. Generaci√≥n y Guardado de Embeddings

M√≥dulo: src/embeddings/generate.py
Proceso:
Lee sample_data.csv (100 registros con userId, teamId, simulationId, type, text, timestamp).
Limpia cada texto y genera embeddings con sentence-transformers/all-MiniLM-L6-v2.
Almacena en Supabase (src/db/connect.py) en la tabla embeddings con columnas: id, userId, teamId, simulationId, type, text, text_hash, embedding, emoticons, timestamp.


Script de Prueba: test_generate_embeddings.py
Procesa los 100 registros y guarda los embeddings.
Muestra los primeros 5 registros (para no saturar la consola).



4. Endpoint para Evitar Duplicaci√≥n

M√≥dulo: main.py
Endpoint: POST /check_embedding
Recibe un JSON con text (por ejemplo, {"text": "Need to fix bugs ASAP"}).
Limpia el texto, calcula su text_hash, y genera su embedding.
Consulta Supabase para verificar si existe un registro con el mismo text_hash.
Respuesta:
Si es duplicado: {"status": "duplicate", "cleaned_text": "...", "existing_record": {...}}
Si es nuevo: {"status": "new", "cleaned_text": "...", "text_hash": "..."}




Prueba: Usar Swagger UI (http://127.0.0.1:8000/docs) para enviar textos y verificar duplicados.

5. Datos de Prueba

Archivo: sample_data.csv
Contiene 100 registros con:
6 usuarios (user123, user456, etc.) en 3 equipos (teamA, teamB, teamC).
Tipos: chat, feedback, reunion.
Textos en espa√±ol e ingl√©s, con emoticones, menciones, y URLs.
Timestamps del 1 al 5 de mayo de 2025.



6. Buenas Pr√°cticas

Limpieza de Datos: Traducci√≥n estandarizada, eliminaci√≥n de ruido (URLs, menciones), preservaci√≥n de acentos y t√©rminos t√©cnicos.
Modularidad: C√≥digo organizado en m√≥dulos (processing, generate, connect) para reusabilidad.
Manejo de Errores: Try-except en scripts para capturar fallos (por ejemplo, conexi√≥n a Supabase).
Documentaci√≥n: Docstrings en funciones y comentarios claros.
Control de Versiones: Commits descriptivos en GitHub.
Seguridad: Credenciales en .env, ignoradas en .gitignore.

Instrucciones para Ejecutar

Clona el repositorio:git clone https://github.com/tu-usuario/no_country_prueba_tecnica.git
cd no_country_prueba_tecnica


Crea un entorno virtual e instala dependencias:python -m venv venv
.\venv\Scripts\Activate.ps1  # Windows
pip install -r requirements.txt


Configura Supabase:
Crea un proyecto en Supabase y habilita PGVector.
Crea la tabla embeddings con las columnas mencionadas.
A√±ade las credenciales (SUPABASE_URL, SUPABASE_KEY) en .env.


Procesa los datos:python test_generate_embeddings.py


Genera y guarda 100 embeddings en Supabase.


Inicia el servidor FastAPI:uvicorn main:app --reload


Accede a http://127.0.0.1:8000/docs para probar el endpoint.



Resultados

Se procesaron 100 registros de sample_data.csv.
Los embeddings se generaron y guardaron en la tabla embeddings de Supabase.
El endpoint /check_embedding detecta duplicados correctamente, retornando el registro existente o confirmando textos nuevos.
Los textos en ingl√©s se traducen a espa√±ol (por ejemplo, "Need to fix bugs ASAP" ‚Üí "necesitar fix bugs asap").
Los emoticones se extraen y almacenan (por ejemplo, "üòä ü•≥").

Limitaciones y Mejoras Futuras

Limitaciones:
El texto limpio (cleaned_text) no se almacena en Supabase, solo se usa para generar text_hash y embedding.
La traducci√≥n puede variar ligeramente para t√©rminos t√©cnicos.


Mejoras:
A√±adir cleaned_text como columna en embeddings.
Implementar an√°lisis de sentimiento para complementar los embeddings.
Optimizar el rendimiento para datasets m√°s grandes.



Conclusi√≥n
La Funcionalidad 1 proporciona una base s√≥lida para an√°lisis sem√°ntico en No Country, con un pipeline completo para limpiar textos, generar embeddings, y evitar duplicados. La soluci√≥n es escalable, cumple con las buenas pr√°cticas, y est√° lista para integrarse con an√°lisis futuros, como la Funcionalidad 2 (an√°lisis de sentimiento y t√≥picos).
